# Day 5: ê³ ê¸‰ Pod ì„¤ì • - Resource Management & QoS

## ğŸ¯ í•™ìŠµ ëª©í‘œ
- Resource Requestsì™€ Limitsì˜ ì°¨ì´ì ê³¼ ì„¤ì • ë°©ë²• ì´í•´
- QoS(Quality of Service) Classesì™€ ìš°ì„ ìˆœìœ„ ì‹œìŠ¤í…œ í•™ìŠµ
- Node Selector, Affinity, Anti-Affinityë¥¼ í†µí•œ Pod ìŠ¤ì¼€ì¤„ë§ ì œì–´
- Taintì™€ Tolerationì„ í™œìš©í•œ ë…¸ë“œ ê²©ë¦¬ êµ¬í˜„

---

## ğŸ“š í•µì‹¬ ê°œë…

### 1. Resource Management ê¸°ì´ˆ

#### Resource Requests vs Limits
- **Requests**: Podê°€ ë³´ì¥ë°›ê³  ì‹¶ì€ ìµœì†Œ ë¦¬ì†ŒìŠ¤
- **Limits**: Podê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ë¦¬ì†ŒìŠ¤

```yaml
resources:
  requests:
    memory: "64Mi"
    cpu: "250m"
  limits:
    memory: "128Mi"  
    cpu: "500m"
```

#### CPU ë¦¬ì†ŒìŠ¤ ë‹¨ìœ„
- **Core ë‹¨ìœ„**: 1 = 1 CPU ì½”ì–´
- **Millicores**: 1000m = 1 ì½”ì–´
- **ì˜ˆì‹œ**: 250m = 0.25 ì½”ì–´, 500m = 0.5 ì½”ì–´

#### Memory ë¦¬ì†ŒìŠ¤ ë‹¨ìœ„
- **Bytes**: Ki(1024), Mi(1024Â²), Gi(1024Â³)
- **Decimal**: K(1000), M(1000Â²), G(1000Â³)
- **ì˜ˆì‹œ**: 128Mi = 134,217,728 bytes

### 2. QoS Classes (Quality of Service)

#### Guaranteed
- **ì¡°ê±´**: requests = limits (ëª¨ë“  ì»¨í…Œì´ë„ˆ)
- **ìš°ì„ ìˆœìœ„**: ê°€ì¥ ë†’ìŒ (ë§ˆì§€ë§‰ì— ì œê±°)
- **ì‚¬ìš© ì‚¬ë¡€**: ì¤‘ìš”í•œ í”„ë¡œë•ì…˜ ì›Œí¬ë¡œë“œ

```yaml
resources:
  requests:
    memory: "200Mi"
    cpu: "700m"
  limits:
    memory: "200Mi"
    cpu: "700m"
```

#### Burstable
- **ì¡°ê±´**: requests < limits ë˜ëŠ” ì¼ë¶€ë§Œ ì„¤ì •
- **ìš°ì„ ìˆœìœ„**: ì¤‘ê°„
- **ì‚¬ìš© ì‚¬ë¡€**: ì¼ë°˜ì ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜

```yaml
resources:
  requests:
    memory: "100Mi"
    cpu: "100m"
  limits:
    memory: "200Mi"
    cpu: "500m"
```

#### BestEffort
- **ì¡°ê±´**: requests, limits ëª¨ë‘ ì„¤ì • ì•ˆí•¨
- **ìš°ì„ ìˆœìœ„**: ê°€ì¥ ë‚®ìŒ (ë¨¼ì € ì œê±°)
- **ì‚¬ìš© ì‚¬ë¡€**: ì¤‘ìš”í•˜ì§€ ì•Šì€ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…

### 3. Pod ìŠ¤ì¼€ì¤„ë§ ì œì–´

#### Node Selector (ê°„ë‹¨í•œ ë…¸ë“œ ì„ íƒ)
```yaml
spec:
  nodeSelector:
    disktype: ssd
    environment: production
```

#### Node Affinity (ê³ ê¸‰ ë…¸ë“œ ì„ íƒ)
```yaml
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/arch
            operator: In
            values:
            - amd64
            - arm64
```

#### Pod Affinity (Pod ê°„ ê´€ê³„ ì„¤ì •)
```yaml
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - database
        topologyKey: kubernetes.io/hostname
```

### 4. Taintì™€ Toleration

#### Taint (ë…¸ë“œì— ì„¤ì •)
```bash
# ë…¸ë“œì— taint ì¶”ê°€
kubectl taint nodes node1 key=value:NoSchedule

# ë…¸ë“œì—ì„œ taint ì œê±°
kubectl taint nodes node1 key=value:NoSchedule-
```

#### Toleration (Podì— ì„¤ì •)
```yaml
spec:
  tolerations:
  - key: "key"
    operator: "Equal"
    value: "value"
    effect: "NoSchedule"
```

---

## ğŸ”§ ì‹¤ìŠµ ê°€ì´ë“œ

### ì‹¤ìŠµ 1: Resource Requests/Limits ì„¤ì •

#### Step 1: Guaranteed QoS Pod ìƒì„±
```bash
# Guaranteed QoS Pod ìƒì„±
kubectl apply -f examples/guaranteed-pod.yaml

# QoS í´ë˜ìŠ¤ í™•ì¸
kubectl describe pod guaranteed-pod | grep -A 5 "QoS Class"
```

#### Step 2: Burstable QoS Pod ìƒì„±
```bash
# Burstable QoS Pod ìƒì„±
kubectl apply -f examples/burstable-pod.yaml

# ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
kubectl top pod burstable-pod
```

#### Step 3: ë¦¬ì†ŒìŠ¤ ë¶€ì¡± ìƒí™© ì‹œë®¬ë ˆì´ì…˜
```bash
# ê³¼ë„í•œ ë¦¬ì†ŒìŠ¤ ìš”ì²­ Pod ìƒì„±
kubectl apply -f examples/resource-intensive-pod.yaml

# Pod ìƒíƒœ í™•ì¸ (Pending ìƒíƒœì¼ ê²ƒ)
kubectl get pods
kubectl describe pod resource-intensive-pod
```

### ì‹¤ìŠµ 2: Node Selectorì™€ Affinity

#### Step 1: ë…¸ë“œì— ë ˆì´ë¸” ì¶”ê°€
```bash
# ë…¸ë“œ ëª©ë¡ í™•ì¸
kubectl get nodes

# ë…¸ë“œì— ë ˆì´ë¸” ì¶”ê°€
kubectl label nodes <node-name> disktype=ssd
kubectl label nodes <node-name> environment=production
```

#### Step 2: Node Selector í…ŒìŠ¤íŠ¸
```bash
# Node Selector Pod ìƒì„±
kubectl apply -f examples/node-selector-pod.yaml

# Podê°€ ì˜¬ë°”ë¥¸ ë…¸ë“œì— ìŠ¤ì¼€ì¤„ë˜ì—ˆëŠ”ì§€ í™•ì¸
kubectl get pod node-selector-pod -o wide
```

#### Step 3: Node Affinity í…ŒìŠ¤íŠ¸
```bash
# Node Affinity Pod ìƒì„±
kubectl apply -f examples/node-affinity-pod.yaml

# ìŠ¤ì¼€ì¤„ë§ ê²°ê³¼ í™•ì¸
kubectl describe pod node-affinity-pod | grep "Node:"
```

### ì‹¤ìŠµ 3: Taintì™€ Toleration

#### Step 1: ë…¸ë“œì— Taint ì„¤ì •
```bash
# ë…¸ë“œì— taint ì¶”ê°€
kubectl taint nodes <node-name> special=true:NoSchedule

# taint í™•ì¸
kubectl describe node <node-name> | grep Taints
```

#### Step 2: Toleration ì—†ëŠ” Pod í…ŒìŠ¤íŠ¸
```bash
# ì¼ë°˜ Pod ìƒì„± (taintëœ ë…¸ë“œì— ìŠ¤ì¼€ì¤„ ë¶ˆê°€)
kubectl apply -f examples/no-toleration-pod.yaml

# Pod ìƒíƒœ í™•ì¸ (Pendingì¼ ê²ƒ)
kubectl get pods
kubectl describe pod no-toleration-pod
```

#### Step 3: Toleration ìˆëŠ” Pod í…ŒìŠ¤íŠ¸
```bash
# Tolerationì´ ìˆëŠ” Pod ìƒì„±
kubectl apply -f examples/toleration-pod.yaml

# ì„±ê³µì ìœ¼ë¡œ ìŠ¤ì¼€ì¤„ë˜ì—ˆëŠ”ì§€ í™•ì¸
kubectl get pod toleration-pod -o wide
```

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ë¶„ì„

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
```bash
# í´ëŸ¬ìŠ¤í„° ì „ì²´ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
kubectl top nodes

# Podë³„ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
kubectl top pods

# íŠ¹ì • ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ Pod ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
kubectl top pods -n kube-system
```

### QoS í´ë˜ìŠ¤ ë¶„ì„
```bash
# ëª¨ë“  Podì˜ QoS í´ë˜ìŠ¤ í™•ì¸
kubectl get pods -o custom-columns=NAME:.metadata.name,QOS:.status.qosClass

# íŠ¹ì • Podì˜ ìƒì„¸ QoS ì •ë³´
kubectl describe pod <pod-name> | grep -A 10 "QoS Class"
```

### ìŠ¤ì¼€ì¤„ë§ ì´ë²¤íŠ¸ í™•ì¸
```bash
# Pod ìŠ¤ì¼€ì¤„ë§ ì´ë²¤íŠ¸ í™•ì¸
kubectl describe pod <pod-name> | grep -A 10 Events

# í´ëŸ¬ìŠ¤í„° ì „ì²´ ì´ë²¤íŠ¸ í™•ì¸
kubectl get events --sort-by='.lastTimestamp'
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­ê³¼ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### Resource ì„¤ì • ê°€ì´ë“œë¼ì¸

#### 1. Requests ì„¤ì • ì›ì¹™
- **ì‹¤ì œ ì‚¬ìš©ëŸ‰ ê¸°ì¤€**: ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ í‰ê·  ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
- **ì—¬ìœ ë¶„ ê³ ë ¤**: í‰ê·  ì‚¬ìš©ëŸ‰ì˜ 110-120% ì„¤ì •
- **ëª¨ë‹ˆí„°ë§ í•„ìˆ˜**: ì‹¤ì œ ì‚¬ìš©ëŸ‰ì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§

#### 2. Limits ì„¤ì • ì›ì¹™
- **ì•ˆì „ ë§ˆì§„**: Requestsì˜ 150-200% ìˆ˜ì¤€
- **ë©”ëª¨ë¦¬ Limits**: OOMKilled ë°©ì§€ë¥¼ ìœ„í•´ ì¶©ë¶„í•œ ì—¬ìœ 
- **CPU Limits**: ë„ˆë¬´ ë‚®ìœ¼ë©´ throttling ë°œìƒ

#### 3. QoS ì„ íƒ ê¸°ì¤€
```yaml
# Critical ì›Œí¬ë¡œë“œ â†’ Guaranteed
resources:
  requests:
    memory: "1Gi"
    cpu: "500m"
  limits:
    memory: "1Gi"
    cpu: "500m"

# ì¼ë°˜ ì›Œí¬ë¡œë“œ â†’ Burstable  
resources:
  requests:
    memory: "512Mi"
    cpu: "250m"
  limits:
    memory: "1Gi"
    cpu: "1000m"

# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… â†’ BestEffort
# (resources ì„¤ì • ì—†ìŒ)
```

### ìŠ¤ì¼€ì¤„ë§ ì „ëµ

#### 1. Node Selector vs Affinity
- **Node Selector**: ê°„ë‹¨í•œ ì¡°ê±´ (í•˜ë‚˜ì˜ ë ˆì´ë¸”)
- **Node Affinity**: ë³µì¡í•œ ì¡°ê±´ (ì—¬ëŸ¬ ë ˆì´ë¸”, ì—°ì‚°ì)

#### 2. Affinity íƒ€ì…
- **RequiredDuringScheduling**: ë°˜ë“œì‹œ ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•¨
- **PreferredDuringScheduling**: ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ ì¢‹ì§€ë§Œ í•„ìˆ˜ëŠ” ì•„ë‹˜

#### 3. Taint/Toleration ì‚¬ìš© ì‚¬ë¡€
- **ì „ìš© ë…¸ë“œ**: GPU ë…¸ë“œ, ê³ ì„±ëŠ¥ ë…¸ë“œ
- **ìœ ì§€ë³´ìˆ˜**: ë…¸ë“œ ë¹„ìš°ê¸° ì „ ìƒˆ Pod ìŠ¤ì¼€ì¤„ë§ ë°©ì§€
- **ë¬¸ì œ ë…¸ë“œ**: ë¬¸ì œê°€ ìˆëŠ” ë…¸ë“œ ê²©ë¦¬

---

## ğŸ§ª ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë¦¬ì†ŒìŠ¤ ìµœì í™”

#### ìƒí™©
- API ì„œë²„: í‰ê·  CPU 200m, ë©”ëª¨ë¦¬ 300Mi ì‚¬ìš©
- íŠ¸ë˜í”½ ê¸‰ì¦ ì‹œ CPU 500m, ë©”ëª¨ë¦¬ 500Miê¹Œì§€ ì‚¬ìš©
- ê°€ìš©ì„±ì´ ì¤‘ìš”í•œ ì„œë¹„ìŠ¤

#### í•´ê²°ì±…
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: optimized-api-server
spec:
  containers:
  - name: api-server
    image: api-server:latest
    resources:
      requests:
        memory: "350Mi"
        cpu: "250m"
      limits:
        memory: "600Mi"
        cpu: "600m"
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ë°ì´í„°ë² ì´ìŠ¤ Pod ì „ìš© ë…¸ë“œ ë°°ì¹˜

#### ìƒí™©
- ë°ì´í„°ë² ì´ìŠ¤ëŠ” SSD ìŠ¤í† ë¦¬ì§€ê°€ ìˆëŠ” ë…¸ë“œì—ë§Œ ë°°ì¹˜
- ë‹¤ë¥¸ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ë¶„ë¦¬ í•„ìš”
- ê³ ì„±ëŠ¥ ë³´ì¥ í•„ìš”

#### í•´ê²°ì±…
```bash
# 1. SSD ë…¸ë“œì— ë ˆì´ë¸” ì¶”ê°€
kubectl label nodes ssd-node-1 storage=ssd
kubectl label nodes ssd-node-1 workload=database

# 2. SSD ë…¸ë“œì— taint ì¶”ê°€ (ë°ì´í„°ë² ì´ìŠ¤ ì „ìš©)
kubectl taint nodes ssd-node-1 workload=database:NoSchedule

# 3. ë°ì´í„°ë² ì´ìŠ¤ Pod ì„¤ì •
```

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: database-pod
spec:
  nodeSelector:
    storage: ssd
  tolerations:
  - key: "workload"
    operator: "Equal"
    value: "database"
    effect: "NoSchedule"
  containers:
  - name: database
    image: postgres:13
    resources:
      requests:
        memory: "2Gi"
        cpu: "1000m"
      limits:
        memory: "2Gi"
        cpu: "1000m"
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ë°°ì¹˜ ì‘ì—… ìŠ¤ì¼€ì¤„ë§

#### ìƒí™©
- ì•¼ê°„ ë°°ì¹˜ ì‘ì—…: ë¦¬ì†ŒìŠ¤ ì§‘ì•½ì 
- í‰ìƒì‹œì—ëŠ” ë‹¤ë¥¸ Podì— ë¦¬ì†ŒìŠ¤ ì–‘ë³´
- ì™„ë£Œë˜ë©´ ìë™ ì •ë¦¬

#### í•´ê²°ì±…
```yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: batch-processing
spec:
  template:
    spec:
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            preference:
              matchExpressions:
              - key: workload-type
                operator: In
                values:
                - batch
      containers:
      - name: batch-processor
        image: batch-processor:latest
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
      restartPolicy: Never
```

---

## ğŸ“ ì •ë¦¬ ë° ë‹¤ìŒ ë‹¨ê³„

### ì˜¤ëŠ˜ í•™ìŠµí•œ ë‚´ìš©
- âœ… Resource Requests/Limits ì„¤ì •ê³¼ QoS Classes
- âœ… Node Selectorì™€ Affinityë¥¼ í†µí•œ Pod ë°°ì¹˜ ì œì–´
- âœ… Taintì™€ Tolerationì„ í™œìš©í•œ ë…¸ë“œ ê²©ë¦¬
- âœ… ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ë³„ ìµœì í™” ì „ëµ

### ì¤‘ìš” í¬ì¸íŠ¸
1. **ë¦¬ì†ŒìŠ¤ ì„¤ì •**: ëª¨ë‹ˆí„°ë§ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì ì ˆí•œ requests/limits
2. **QoS ì´í•´**: ì›Œí¬ë¡œë“œ ì¤‘ìš”ë„ì— ë”°ë¥¸ QoS í´ë˜ìŠ¤ ì„ íƒ
3. **ìŠ¤ì¼€ì¤„ë§**: ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” Pod ë°°ì¹˜ ì „ëµ
4. **ë…¸ë“œ ê´€ë¦¬**: Taint/Tolerationì„ í†µí•œ íš¨ìœ¨ì ì¸ ë¦¬ì†ŒìŠ¤ í™œìš©

### ë‹¤ìŒ í•™ìŠµ (Day 6)
- ì „ì²´ ë¦¬ì†ŒìŠ¤ë¥¼ í™œìš©í•œ í†µí•© í™˜ê²½ êµ¬ì„±
- ì‹¤ì „ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ë° ìš´ì˜
- ëª¨ë‹ˆí„°ë§ê³¼ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ì‹¤ìŠµ

---

## ğŸ”— ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [Managing Resources for Containers](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)
- [Assigning Pods to Nodes](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/)
- [Taints and Tolerations](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)

### ëª¨ë‹ˆí„°ë§ ë„êµ¬
- `kubectl top`: ê¸°ë³¸ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
- `kubectl describe`: ìƒì„¸ ì •ë³´ ë° ì´ë²¤íŠ¸ í™•ì¸
- Metrics Server: í´ëŸ¬ìŠ¤í„° ë©”íŠ¸ë¦­ ìˆ˜ì§‘

### ì‹¤ë¬´ íŒ
- Resource ì„¤ì •ì€ ì ì§„ì ìœ¼ë¡œ ì¡°ì •
- ëª¨ë‹ˆí„°ë§ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì˜ì‚¬ê²°ì •
- ê°œë°œ/ìŠ¤í…Œì´ì§•/í”„ë¡œë•ì…˜ í™˜ê²½ë³„ ë‹¤ë¥¸ ì„¤ì •